[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "anteemony.github.io",
    "section": "",
    "text": "Machine Learning for Everyone\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nNo ML Degree - Part Three Notes\n\n\n\n\n\n\n\n\n\n\n\n\nJan 7, 2024\n\n\nAnthony Okonneh\n\n\n\n\n\n\n  \n\n\n\n\nNo ML Degree - Introduction Notes\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nAnthony Okonneh\n\n\n\n\n\n\n  \n\n\n\n\nNo ML Degree - Part Two Notes\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nAnthony Okonneh\n\n\n\n\n\n\n  \n\n\n\n\nNo ML Degree - Part One Notes\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nAnthony Okonneh\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nHello World!\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2023\n\n\nOkonneh Anthony\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 25, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Part Three Notes.html",
    "href": "posts/No ML Degree/No ML Degree - Part Three Notes.html",
    "title": "No ML Degree - Part Three Notes",
    "section": "",
    "text": "Notes from the book No ML Degree by Emil Wallner\nThe guide provided is for self-learners looking for their first ML job. But is also valuable for recent graduates and ML practitioners who want to stay up to date as ML evolves.\nHere’s what the career journey of a self-learner can look like."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Part Three Notes.html#weak-portfolio-projects",
    "href": "posts/No ML Degree/No ML Degree - Part Three Notes.html#weak-portfolio-projects",
    "title": "No ML Degree - Part Three Notes",
    "section": "❌Weak Portfolio Projects",
    "text": "❌Weak Portfolio Projects\nTypical weak portfolio projects include listing toy problems on your resume such as:\n\nMNIST\nTitanic\nIris\n\nFor many employers, that’s an instant rejection as those are considered school projects and don’t require talent or endurance to solve.\nSome ML projects have neither a positive nor negative impact on your resume. They are comparable to blank portfolio items. This might sound harsh, but these are often the most common ML projects. These portfolio items are often too hard to evaluate or lack results. For example,\n\nA stock prediction app\nA GAN to generate artwork\nReinforcement learning applied to a game\nCancer prediction model\n\nMany recruiters will see 5-10 people with the same portfolio projects on any given day.\nThese could be great projects, but they lack enough information to inform a recruiter. Self-learners are often naive. They don’t have experience competing against candidates that lack integrity. (Fake portfolio applicants)\nSelf-learners need to differentiate themselves from fake and low-effort portfolios."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Part Three Notes.html#degree-equivalent-portfolio-projects",
    "href": "posts/No ML Degree/No ML Degree - Part Three Notes.html#degree-equivalent-portfolio-projects",
    "title": "No ML Degree - Part Three Notes",
    "section": "Degree Equivalent Portfolio Projects",
    "text": "Degree Equivalent Portfolio Projects\nA non-expert recruiter needs HARD EVIDENCE that you didn’t copy-paste your projects. It’s your responsibility to create the evidence equal to a degree. Three great options when it comes to clear result-based portfolio items include (see High Effort Projects) :\n\nHigh-ranking score in an ML competition.\nA contribution to a popular ML open-source project\nA published paper / workshop paper (mostly relevant for transitioning STEM researchers)\n\nThese may be hard to achieve for your first portfolio, but it’s worth knowing what to aim for. There are three more result-based portfoio items, but they require effort for recruiters to understand, thus less valuable than the previous three categories :\n\nAn ML project with real users (ideally a deployed model with a UI)\nIndustry-specific solution with a mentor that provides a testimonial (see Industry Portfolio Projects)\nML content marketing with high engagement such as blogging, podcasts, and videos (developer advocacy roles)\n\n\nHigh-effort Projects\n\nHigh-ranking score in an ML competition. e.g. Kaggle competitions sponsored by known companies\nA contribution to a popular ML open-source project e.g. Popular Libraries such as Scikit Learn, Tensorfolow, Numpy or Pytorch.\nA published paper / workshop paper (mostly relevant for transitioning STEM researchers) e.g. NeurlPS, ICLR and ICLM\n\nThese are easy to understand as a high-effort signal. But these are hard to achieve given the timeframe self-learners have.\nMore achieveable results would be:\n\nHigh-ranking score in smaller ML competitions. e.g. More niche competitions on Kaggle, Numerai, ML conference competitions or company competitions. It’s better to have a top ranking in a small competition than to be average in a large competition.\nA published paper / workshop paper in NeurlPS, ICLM, and ICLR or a published paper in any other mL conference.\nContributions to a up-and-coming ML open-source projects. (best way to collaborate and get to know people who work in ML) e.g. FFCV, EleutherAI, Hugging Face, Pytorch Lightning, LAION, Replicate, timm, Segmentation Models, OpenAI, Gym, Albumenations, einops, ONNX JS, FLAX and the FastAI Library. These projects are done by some of the most talented people in the industry, and they are often looknig for people to help.. They might even have solid first issues listed in their GitHub repos.\n\nThese portfolio items will require a lot of hard and focused work. But these systems are meritocratic. Good work will be recognized.\n\n\nIndustry Portfolio Projects\nWorking with someone int the industry to solve a real problem and have them write a testimonial is a safe and solid portfolio project. However, unless ouhave someone that vouches for your solution, it’s not a result-based project.\nHow to find someone to work with (Hard part) * Email 10-20 engineers at startups you respect. Ask them for industry problems with accessisble data that you can tackle. A good place to find prospects are people on Twitter with less than 10k followers and a blog. Here’s an example email.\nTitle: Industry ML problems\n    Hi Jane, \n    \n    I'm self-studying deep learning [Link to github] and I'm looking for problems I can tackle for my portfolio. \n    \n    Given your interesting work on Twitter's recommendatation system [link to their blog], I thought you could have exposure oto other unique industry problems.\n    \n    I;m thinking of using Twitter's API to odo an NLP analysis to detect the percentage of bot on Twitter. Is that a good entry-level problem to tackle or can you think of something else?\n    \n    Cheers, \n    \n    Bob\nKeep it short, indicate that you have done your homework, and give them an easy way out. If you translate their feedback into results, they’ll be happy to keep helping you.\nWhen you have worked hard on the problem and have a great result, yoou can pint them agin and ask for feeback on the project. ML engineers can both put you in a good starting point, scope the porject, help you when you get stuck, and potentially hire or recommend you later.\n\nAnother way to find someone to work with is by approahing people that post data-related freelance projects on freelancer marketplaces and look at sites that post pro-bono data projects."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Introduction Notes.html",
    "href": "posts/No ML Degree/No ML Degree - Introduction Notes.html",
    "title": "No ML Degree - Introduction Notes",
    "section": "",
    "text": "Notes from the book No ML Degree by Emil Wallner\nThe guide provided is for self-learners looking for their first ML job. But is also valuable for recent graduates and ML practitioners who want to stay up to date as ML evolves.\nHere’s what the career journey of a self-learner can look like."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Introduction Notes.html#the-recipe-to-fail",
    "href": "posts/No ML Degree/No ML Degree - Introduction Notes.html#the-recipe-to-fail",
    "title": "No ML Degree - Introduction Notes",
    "section": "The Recipe To Fail",
    "text": "The Recipe To Fail\n\nEffective self-learning mimics what ML professionals do on a daily basis.\nAs a self learner, do not do the opposite of this. Do not get stuck in long lists of online courses and certifications.\nOnline courses have a small impact on employment attractiveness. Same with certifications as there is no way to tell if you really worked for it or cheated.\nThe problem with certifications also applies to portfolios. Many applicants copy-paste or tweak existing projects so it’s hard to tell the difference between real and low-effort projects.\nFor companies, it’s too risky to advance candidates without evidence of being hireable.\nPopular positions are your first option, but you are not their first. With hundereds or even thousands of applicants per position, the resume lotteries favour the university graduates.\nThis rejection makes self learners lose motivation and confidence. They begin to feel overwhelmed with all that’s to be learned in order to get a job.\nThere are far better ways to land an ML job."
  },
  {
    "objectID": "posts/hello-world/hello world.html",
    "href": "posts/hello-world/hello world.html",
    "title": "Hello World!",
    "section": "",
    "text": "Hello World!"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/ML4E/ML4E Notes.html",
    "href": "posts/ML4E/ML4E Notes.html",
    "title": "Machine Learning for Everyone",
    "section": "",
    "text": "In simple words. With real-world examples. Notes taken from vas3k’s blog"
  },
  {
    "objectID": "posts/ML4E/ML4E Notes.html#how-ml-is-popularly-protrayed.",
    "href": "posts/ML4E/ML4E Notes.html#how-ml-is-popularly-protrayed.",
    "title": "Machine Learning for Everyone",
    "section": "How ML is popularly protrayed.",
    "text": "How ML is popularly protrayed."
  },
  {
    "objectID": "posts/ML4E/ML4E Notes.html#why-do-we-want-machines-to-learn",
    "href": "posts/ML4E/ML4E Notes.html#why-do-we-want-machines-to-learn",
    "title": "Machine Learning for Everyone",
    "section": "Why do we want machines to learn?",
    "text": "Why do we want machines to learn?\nBilly x Regression"
  },
  {
    "objectID": "posts/ML4E/ML4E Notes.html#three-components-of-machine-learning.",
    "href": "posts/ML4E/ML4E Notes.html#three-components-of-machine-learning.",
    "title": "Machine Learning for Everyone",
    "section": "Three components of Machine Learning.",
    "text": "Three components of Machine Learning.\nThe only goal of machine learning is to predict results based on incoming data. That’s it. All ML tasks can be represented this way, or it’s not an ML problem from the beginning.\nThe greater variety in the samples you have, the eaisier it is to find relevant patterns and predict the result. Therefore, we need three components to teach the machine.\n\nData -&gt; Want to predict something? Get samples of that thing! The more diverse the data, the better the result. Tens of thousands of rows is the bare minimum for the desperate ones.\nFeatures -&gt; (parameters / variables) The factors for a machine to look at e.g. car mileage, user’s gender, stock price etc. Also feature selection is the most time consuming ML part and also the main source of errors\nAlgorithm -&gt; Any problem can be solved differently. The method you choose affects the precision, performance, and size of the final model. But if the data is crappy, even the best algorithm won’t help.\n\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/ML4E/ML4E Notes.html#supervised-learning",
    "href": "posts/ML4E/ML4E Notes.html#supervised-learning",
    "title": "Machine Learning for Everyone",
    "section": "1.1. Supervised Learning",
    "text": "1.1. Supervised Learning\nClearly, the machine will learn faster with a teacher, so it’s commonly used in real-life tasks. There are two types of such tasks:\n\nClassification -&gt; An object’s category prediction\nRegression -&gt; A prediction of a specific point on a numeric axis\n\n\nClassification\nSplits objects based on one of the attributes specified before hand. e.g Separate documents based on language, music by genre etc.\nToday used for:\n\nSpam Filtering\nLanguage Detection\nA search of similar documents\nSentiment Analysis\nRecognition of hand written characters and numbers\nFraud detection\n\nPopular classification algorthms:\n\nNaive-Bayes\nDecision Tree\nLogistic Regression\nK-Nearest Neighbours\nSupport Vector Machine\n\nToday, Neural Networks are more frequently used for classification, as that’s what they were created for.\nThe rule of thumb is that the more complex the data, the more complex the algorithm. So you would want to use the classical approach for text, numbers and tables. The models are smaller there, they work faster and work more clearly. For pictures, video and all other complicated big data things, you should definitely look at neural networks.\n\n\nRegression\n“Draw a line through these dots. Yep, that’s the machine learning.”\nRegression is basically classification where we forecast a number instead of a category e.g. car price by it’s mileage, traffic by time of the day, demand volume by growth of the company etc. Regression is perfect when something depends on time.\nToday, this is used for,\n\nStock price forecasts\nDemand and sales volume analysis\nMedical Diagnosis\nAny number-time correlations\n\nPopular Algorithms are\n\nLinear Regression (when the line is straight)\nPolynomial Regression (when the line is curved)\n\nEveryone who works in finance and analysis loves Regression. \nIt’s okay to mess with regression and classification, though. Many classifiers turn into regression after some tuning. We can not only define the class of the object but memorize how close it is. Here comes a regression."
  },
  {
    "objectID": "posts/ML4E/ML4E Notes.html#unsupervised-learning",
    "href": "posts/ML4E/ML4E Notes.html#unsupervised-learning",
    "title": "Machine Learning for Everyone",
    "section": "1.2 Unsupervised Learning",
    "text": "1.2 Unsupervised Learning\nUnsupervised Learning was invented a bit later, in the 90’s. It is used less often, but sometimes we simply have on choice.\nLabeled data is a luxury. Trying to create a bus classifier? Using unsupervised learning instead of taking a picture of every bus in existence is a great option.\nBut the author can not remember any good practical application for unsupervised learning. It’s actually useful for exploratory data analysis, but not as the main algorithm.\n\nClustering\n“Divide objects based on unknown features. Machine chooses the best way.”\nNowadays used: * For marketing segmentation (types of customers, loyalty) * To merge close points on a map * For image compression * To analyse and label new data * To detect abnormal behaviours\nPopular Algorithms include:\n\nK-means clustering\nMean-shift\nDBSCAN\n\nClustering is a classification with no pre-defined classes. It’s like dividing socks by colour when you don’t remember all the colours that you have. Clustering algorithms try to find similar (by some features) objects and merge them in a cluster. Those who have similar features are joined in one class. With some algorithms, you can even specifiy the exact number of clusters you want.\nExamples of clustering include markers on web maps, Gallery (facial) grouping, image compression.\n\n\nDimensionality Reduction (Generalization)\n“Assembles specific features into high-level ones”\nNowadays is used for:\n\nRecommender Systems (*)\nBeautiful visualizations\nTopic modelling and similar document search\nFake image analysis\nRisk Management\n\nPopular Algorithms:\n\nPrincipal Component Analysis (PCA)\nSingular Value Decomposition (SVD)\nLatent Dirichlet allocation (LDA)\nLatent Semantic Analytics (LSA, pLSA, GLSA)\nt-SNE (for visualization)\n\n\n\nAssociation Rule Learning\n“Look for patterns in the orders’ stream”\nThis includes all the methods to analyze shopping carts, automate marketing strategy and other event-related tasks.\nNowadays is used:\n\nTo forecast sales and discounts\nTo analyze goods bought together\nTo place the products on the shelves\nTo analyze web surfing patterns\n\nPopular algorithms include:\n\nApriori\nEuclat\nFP-growth"
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Part Two Notes.html",
    "href": "posts/No ML Degree/No ML Degree - Part Two Notes.html",
    "title": "No ML Degree - Part Two Notes",
    "section": "",
    "text": "Notes from the book No ML Degree by Emil Wallner\nThe guide provided is for self-learners looking for their first ML job. But is also valuable for recent graduates and ML practitioners who want to stay up to date as ML evolves.\nHere’s what the career journey of a self-learner can look like."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Part Two Notes.html#learning-machine-learning",
    "href": "posts/No ML Degree/No ML Degree - Part Two Notes.html#learning-machine-learning",
    "title": "No ML Degree - Part Two Notes",
    "section": "Learning Machine Learning",
    "text": "Learning Machine Learning\nThe are two challenges:\n\nHaving a good enough resume to get interviews (Focus on this)\nPassing the interview and getting an offer.\n\nIt’s unreasonable to both have a strong no-degree resume and also be competitive in theory-heavy interviews.\nThere are enough ML opportunities that have practical interviews and light theroy requirements. It’s best to focus on those gigs and maintain momentum. Work experience will give you a significant boost in later job hunts.\nSo the goal for those three months are to:\n\nLearn data-centric problem-solving tools.\nIdentify, scope, communicate and solve problems.\nBuild a portfolio with externally validated results.\nGain a light overview of ML and statistics.\n\nA strong portolio weighs heavier than a boot camp graduation. Boot camps can be inconvenient and expensive also.\n\nNano Degrees\n\nCloud Specific ML Certificates(Customer-centric roles for specific cloud providers find this useful)\n\nGCP\nAzure\nAWS\n\n\nPractical ML Courses\nPick a practical ML course and study it for one month. You might think that one month of ML is not enough to build your projects. But it is. You’ll be rusty and need to check things frequently, but you have enough to start soving data problems.\nSolid practical ML courses for coders include:\n\nFastAI\nKaggle’s 30 days of code.\n\nIt’s less important if you use a paid solution, an open-source library, write models from scratch or know all the theory.\nWhat matters is spotting potential risks and weaknesses with your solutions and lerning how to mitigate them. That’s what modern learning is.\nThe things you want to learn include:\n\nProblem Solving\n\nKnow the domain of problems ML can and can’t solve.\nKnow when you should use paid APIs, open-source or custom solutions.\nBasic Awareness of how your model impacts a business including privacy, UI/UX, legal, ethics and their business model.\nCommunicating expectations and timelines to technical and non-technical stakeholders.\nHow and when to mitigate risk from your inexperience.\n\n\n\nData\n\nUnderstanding what data is available to you and how to get more.\nExtracting, visualizing, cleaning and loading data.\nUnderstand the data and make informed decisions based on it.\n\n\n\nModels\n\nUnderstanding the type of problem and how to find a solution.\nSetting and measuring appropriate objectives and success criteria.\nQuickly reaching a baseline.\nTraining models with state-of-the-art results.\nFast and efficient debugging.\nVisualizing model performance.\nDeploying models and understanding memory, cost, queries-per-second, and latency.\n\nThis might seem like a lot, but they are often a byproduct of building an industry-standard portfolio.\nAfter your month-long practical course including looking things up on various sources, your focus should be 90% on your portfolio.\nYou need a resume as soon as possible.\n\n\n\nBreadth, Credibility, and Edge\nDeep Learning is the most exciting area and as the most future potential. Classic machine learning approaches are rarely used by the author although they are common in the industyr and are often used in interviews.\nIn the evenings, it’s worth exploring one or two videos from:\n\nStatQuests’ the Basics (of statistics)\nStatQuests’ the Basics of Mahcine Learning\n\nYou can use Anki to memorize the key concepts in these videos.\nThis enables you to acquire a vocabulary and mindset that’s often used to discuss data-related problems. Having a light overview also makes you aware of certain risks and wher you can learn more to mitigate them.\nFor your portfolio, you have two types of portfolio projects:\n\nDegree equivalent projects ( 1-3 months long result-driven projects that give you credibility )\nTalent projects ( 1-4 week open projects that make you stand out )\n\nThe first is what makes employers invite you to interviews, They give you evidence that you can do the job. Talent projects are both great for marketing yourself and making you stand out in the interview process.\nHowever, if you only have shiny talent projects, many employers will doubtthat you can do the daily grunt work to deliver on projects."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Part One Notes.html",
    "href": "posts/No ML Degree/No ML Degree - Part One Notes.html",
    "title": "No ML Degree - Part One Notes",
    "section": "",
    "text": "Notes from the book No ML Degree by Emil Wallner\nThe guide provided is for self-learners looking for their first ML job. But is also valuable for recent graduates and ML practitioners who want to stay up to date as ML evolves.\nHere’s what the career journey of a self-learner can look like."
  },
  {
    "objectID": "posts/No ML Degree/No ML Degree - Part One Notes.html#programming-paths",
    "href": "posts/No ML Degree/No ML Degree - Part One Notes.html#programming-paths",
    "title": "No ML Degree - Part One Notes",
    "section": "Programming Paths",
    "text": "Programming Paths\nRegardless of which programming path you choose, aim for at least 6 - 24 months of study and work experience in order to get a good foundation\n\nNo-degree Tech Schools and Online Courses\n\nCodeacademy\nScrimba\nfreeCodeCamp\n42 network (peer-to-peer)\nHolberton School (an alternative to 42 network)\n\n\n\nBoot Camps\n\nHigh Ranking Boot Camps\n\n\n\nComputer Science\n90% of today’s models are trained and deployed on servers. Most of the work is focused on making the data, training and production process faster by improving efficiency and organization.\nA practical CS curriculum with a focus on projects and programming is a solid base. Specializations include security, DevOps, back-end, and graphics. Work with Python as you’ll mostly be working with it when you move into ML.\n\n\nFront-end and Mobile\nLess common entries into ML, but still with benefits. e.g. cost, latency and privacy benefits to running ML models on personal computers and phones. Client inference and optimization are valid entry-points into ML. Although only 10% of the ML inference happens on the client today, it is expected to increase in the near future.\nThe major shifts in the client-side are: * Human-in-the-loop * Prompt engineering * Active learning * Creating smaller intermediate models, workflows and programs to interact with server-side models is important. * It’s worth looking into Neural Radience Fields and Browser Rendering.\nOn the tech side, look into * TensorflowJS, * ONNX.JS * Eigen (C++) compiled with Web Assembly * PyScript"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Anthony Okonneh",
    "section": "",
    "text": "About this blog\nMachine Learning & Deep Learning topics."
  }
]